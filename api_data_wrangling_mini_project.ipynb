{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from the Qunadl API. Qaundl is currently the most widely used aggregator of financial market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the http://www.quandl.com website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "# Store the API key as a string - according to PEP8, constants are always named in all upper case\n",
    "API_KEY = config.mykey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaundl has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Quandl API instructions here: https://docs.quandl.com/docs/time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Quandl API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/ ).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: API's can change a bit with each version, for this exercise it is reccomended to use the \"V3\" quandl api at `https://www.quandl.com/api/v3/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  {'id': 46157199, 'dataset_code': 'SE7', 'database_code': 'XFRA', 'name': 'Seiko Epson Corp (SE7) Adjusted Stock Prices', 'description': ' <b>Ticker</b>: SE7 <br> <br> <b>Exchange</b>: XFRA <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in EUR currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.', 'refreshed_at': '2022-01-29T03:52:02.543Z', 'newest_available_date': '2018-11-30', 'oldest_available_date': '2007-01-02', 'column_names': ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adjustment Factor', 'Adjustment Type'], 'frequency': 'daily', 'type': 'Time Series', 'premium': True, 'limit': None, 'transform': None, 'column_index': None, 'start_date': '2017-01-02', 'end_date': '2017-01-02', 'data': [['2017-01-02', 16.541989, 16.541989, 16.541989, 16.541989, 0.0, None, None]], 'collapse': None, 'order': None, 'database_id': 15302}\n"
     ]
    }
   ],
   "source": [
    "# Now, call the Quandl API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned\n",
    "url =  \"https://data.nasdaq.com/api/v3/datasets/XFRA/SE7?start_date=2017-01-02&end_date=2017-01-02&api_key=\"+API_KEY\n",
    "r = requests.get(url)\n",
    "json_data = r.json()\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Alter URL for an entire year\n",
    "url =  \"https://data.nasdaq.com/api/v3/datasets/XFRA/SE7?start_date=2017-01-01&end_date=2017-12-31&api_key=\"+API_KEY\n",
    "r = requests.get(url)\n",
    "dictdata = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Highes and Lowest openning prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.895015\n",
      "15.360317\n"
     ]
    }
   ],
   "source": [
    "n = len(dictdata['dataset']['data'])\n",
    "prices = [dictdata['dataset']['data'][i][1] for i in range(n)]\n",
    "max_p = max(prices)\n",
    "min_p = min(prices)\n",
    "print(max_p)\n",
    "print(min_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find largest change in any one day based on High and Low Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5644690000000026\n"
     ]
    }
   ],
   "source": [
    "chnge = [dictdata['dataset']['data'][i][2]- dictdata['dataset']['data'][i][3] for i in range(n)]\n",
    "max_chnge = max(chnge)\n",
    "print(max_chnge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjacent Day Biggest Change (plus or minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6527519999999996\n"
     ]
    }
   ],
   "source": [
    "adjDay = [dictdata['dataset']['data'][i][4]- dictdata['dataset']['data'][i+1][4] for i in range(n-1)]\n",
    "absLst = list(map(abs, adjDay))\n",
    "maxAbsChng = max(absLst)\n",
    "print(maxAbsChng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Daily Trading Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.03076923076924\n"
     ]
    }
   ],
   "source": [
    "avgVol = sum([dictdata['dataset']['data'][i][5] for i in range(n)])/len([dictdata['dataset']['data'][i][5] for i in range(n)])\n",
    "print(avgVol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Trading Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def median(aList):\n",
    "    aList.sort()\n",
    "    n = len(aList)\n",
    "\n",
    "    if n % 2 == 0: \n",
    "        med = (aList[int(n/2)-1] + aList[int(n/2)])/2\n",
    "    else:\n",
    "        med = aList[int((n-1)/2)]\n",
    "    return(med)\n",
    "\n",
    "clsVol = [dictdata['dataset']['data'][i][5] for i in range(n)]\n",
    "\n",
    "print(median(clsVol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### These are your tasks for this mini project:\n",
    "\n",
    "#### Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "#### Convert the returned JSON object into a Python dictionary.\n",
    "#### Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "#### What was the largest change in any one day (based on High and Low price)?\n",
    "#### What was the largest change between any two days (based on Closing Price)?\n",
    "#### What was the average daily trading volume during this year?\n",
    "#### (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
